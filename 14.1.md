## 14.1 토큰 절약을 위한 프롬프트 전략

OpenAI API를 활용한 서비스에서는 호출 빈도가 늘어날수록 사용량 증가에 따른 비용 부담이 커질 수 있습니다. 특히 Chat Completions, Embeddings, Assistants API 등 다양한 프롬프트 기반의 인터페이스는 입력 및 출력되는 텍스트의 토큰 수(token count)에 따라 비용이 책정됩니다. 따라서 “효율적인 토큰 활용”은 OpenAI API 기반 애플리케이션의 운영에서 핵심적인 최적화 과제입니다.

본 절에서는 불필요한 토큰 소모를 줄이기 위한 실질적인 전략을 다양한 사례와 함께 소개합니다. 여기서 다루는 대부분의 전략들은 Chat Completions API 기준이지만, Embedding API나 기타 API에도 동일한 원리가 영향을 미칩니다.



### 1. 토큰이란 무엇인가? (간단한 정리)

OpenAI API에서의 "토큰"은 텍스트 단위를 의미하며, 영어 기준으로는 보통 1~2개의 짧은 단어에 해당합니다:

- 예: "OpenAI is powerful." → 5 tokens
- 한국어: 한글은 영어보다 상대적으로 더 많은 토큰을 차지할 수 있음
- GPT 모델의 tokenizer는 cl100k_base (GPT-4 및 GPT-3.5-turbo 모델에서 사용)를 기준

정확한 토큰 수를 알기 위해서는 다음과 같은 도구를 활용할 수 있습니다:

- OpenAI Tokenizer 웹 도구: https://platform.openai.com/tokenizer
- tiktoken Python 라이브러리 (OpenAI 제공)

따라서, 본 절에서 소개하는 토큰 절약 전략은 곧 비용 절감과도 직결됩니다.



### 2. 효율적인 시스템 프롬프트 설계

시스템 프롬프트(system message)는 AI의 전반적인 성향을 조절하는 중요한 도구이지만, 지나치게 길거나 반복되는 내용을 포함하면 불필요한 토큰 낭비가 발생합니다.

✅ 최적화 원칙:

- ✔️ 시스템 프롬프트는 간결하고 명확하게 작성
- ✔️ 불필요한 문장 반복 제거 ("당신은 최고의 AI입니다." 등의 찬사성 꾸밈말 불필요)
- ✔️ 역할 지시만 간단명료하게:  
  예: "당신은 한국어 교정 전문가입니다. 사용자의 문장을 문법과 어투 측면에서 자연스럽게 수정하세요."

🔍 예시 비교:

| 과도한 프롬프트 | 최적화된 프롬프트 |
|------------------|------------------|
| "당신은 세계 최고의 언어 전문가이며, 엄청난 지식과 경험을 지닌 AI입니다. 전 세계 수억 명의 사람들이 신뢰하는 GPT이며..." | "당신은 한국어 문법 교정 전문가입니다. 문장을 더 자연스럽고 정확하게 만드세요." |



### 3. 불필요한 대화 이력 생략하기

Chat Completions API에서는 사용자의 모든 대화 이력이 token으로 계산됩니다:

- 메시지를 보내는 user/assistant/system의 모든 메시지는 누적됨
- 긴 대화일수록 이전 메시지 맥락 유지 비용 증가

✅ 전략:

- 🌐 간단한 태스크에서는 이전 메시지를 제외하고 호출
- 🧠 요약된 대화 기록을 메모리로 관리해 전달 (최근 사용자 질문 요약문 전달 등)
- 🔃 메시지 교환 횟수가 많은 챗봇에서는 대화 히스토리 슬라이딩 윈도우 기법 적용 (최근 N건만 유지)

📌 예:

```python
# 사용자가 길게 대화한 예: messages 길고 토큰 낭비
messages = [
  {"role": "system", "content": "너는 책 추천 전문가야"},
  {"role": "user", "content": "나는 예전에 셜록홈즈를 재밌게 읽었어"},
  {"role": "assistant", "content": "추리소설을 좋아하시나 보군요. 어떤 분위기를 선호하세요?"},
  {"role": "user", "content": "약간 어둡지만 몰입감 있는 스토리면 좋겠어"},
]

# 최적화된 형태: user 최근 요청 + 요약된 정보만 포함
messages = [
  {"role": "system", "content": "너는 책 추천 전문가야"},
  {"role": "user", "content": "셜록홈즈처럼 어둡고 몰입감 있는 소설 추천해줘"},
]
```



### 4. 간결하고 정형화된 프롬프트 사용

AI 응답을 위한 질문은 종종 "장황하게 설명된" 프롬프트로 구성됩니다. 하지만 간결하고 목적이 명확한 프롬프트가 같은 효과를 유지하면서도 훨씬 적은 토큰을 소모할 수 있습니다.

✅ 전략:

- ❌ "이 문장을 좀 더 간결하고 세련된 문장으로 바꿔주실 수 있으신가요?"
- ✅ "이 문장을 더 간결하게 바꿔줘:"

👉 이렇게 문장의 목적이 분명할수록 토큰 수 절약 + 모델 응답 품질 좋음

📌 예시:

| 나쁜 예 | 좋은 예 |
|--------|--------|
| "다음 문장을 더 자연스럽고 존댓말 형태로 고쳐주세요: '나는 점심을 먹었어.'" | "다음 문장을 존댓말로 고쳐줘: '나는 점심을 먹었어.'" |



### 5. 출력 토큰 수 제한: max_tokens 활용

OpenAI API는 응답 길이를 제어하기 위한 max_tokens 파라미터를 제공합니다.

✅ 전략:

- 분석/설명 등 내용이 길어질 수 있는 출력에는 max_tokens를 명확히 지정
- 사용자 요약, 한 줄 응답 등에선 max_tokens=50 등 적절한 제한

📌 예:

```python
response = openai.ChatCompletion.create(
  model="gpt-4",
  messages=messages,
  max_tokens=100,   # 100 토큰 이상은 생성하지 않음
  temperature=0.7
)
```

💡 max_tokens는 “출력” 길이에만 영향을 미침. 입력 토큰은 이미 메시지(messages) 길이로 고정되어 있음.



### 6. 불변 텍스트는 클라이언트에서 처리

사용자에게 반복적으로 노출할 일정한 안내문이나 서론은 AI의 출력으로 포함하지 않도록:

- 예: "안녕하세요, 무엇을 도와드릴까요?"는 매번 AI가 말하게 하지 말고, 클라이언트에서 프론트 UI에 고정 출력

✅ 전략:

- UX 문장은 클라이언트 UI에서 처리
- 중복되는 첫머리·꼬리말 제거



### 7. JSON / Structured 출력 유도

GPT로부터 구조화된 출력을 받게 되면, 불필요한 설명, 인삿말, 자연어 출력 등을 줄일 수 있어 토큰 사용을 줄이는 데 매우 유리합니다.

✅ 전략:

- system 프롬프트에 “JSON 형태로만 출력해라” 명시
- ChatCompletion 파라미터 json_mode 활성화 (gpt-3.5-turbo-1106 이상에서 지원)

📌 예시:

```python
{
  "role": "system",
  "content": "출력은 반드시 다음 JSON 형식을 따르세요: {\"title\": ..., \"summary\": ...}"
}
```

➡️ GPT가 불필요한 자연어 설명 없이 키-값 구조만 출력함 → 응답 토큰 절약



### 8. Embedding 전에 텍스트 압축/요약

Embedding API 또한 입력된 텍스트 전체 길이를 기준으로 토큰이 과금됩니다.

✅ 전략:

- 긴 문서를 embedding 전 미리 요약 또는 heading-별 분할
- 중복 표현 제거 (예: “본 문서에서는... 본 보고서에서는...” 등 무효 표현)
- 많은 문장이나 단락이 반복되는 구조의 경우, 유사문 제거 또는 Clustering 후 대표 벡터화



### 9. Markdown, HTML 요소 제거 또는 최소화

GPT API를 통해 마크다운 또는 HTML 처리를 하는 경우에도, 태그들이 토큰 수 증가에 크게 기여합니다.

예:

```markdown
**이것은 굵은 글씨입니다** → 6~8개의 토큰  
<ul><li>아이템1</li></ul> → 20~30 토큰 이상
```

✅ 전략:

- 텍스트 기반 요약/분석에는 태그 제거 후 입력 처리
- 필요시 출력만 Markdown/HTML 로 client-side에서 렌더링 처리



## ✅ 요약 정리: 토큰 절약 체크리스트

| 항목 | 설명 | 적용 대상 |
|------|------|------------|
| 시스템 프롬프트 최소화 | 간결하고 목적지향적으로 작성 | 모든 Chat API |
| 대화 이력 축소 | 슬라이딩 윈도우, 요약기반 유지 | Chat 기반 챗봇 |
| 프롬프트 간결화 | 중복 표현, 장문 요청 줄이기 | QA, 설명형 요청 |
| max_tokens 설정 | 출력 길이 제한 | 불확실 응답 |
| 클라이언트 서문 분리 | 반복 UI 안내는 직접 렌더링 | 모든 응용 |
| JSON 출력 구조화 | structured output 강제 | GPT 응답 형식화 |
| Embedding 전 요약 | 입력 토큰 회피 | 문서 검색 기반 시스템 |
| 불필요한 태그 제거 | HTML/Markdown 렌더링 최소화 | 수집 웹문서 |

이러한 전략을 종합적으로 활용하면, ChatGPT 계열 API의 비용 및 반응 속도를 크게 최적화할 수 있습니다. 다음 절인 14.2에서는 Embedding과 관련된 토큰 절약 및 성능 최적화 전략을 더욱 심화해서 다룹니다.