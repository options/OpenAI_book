## 18.3 한국/유럽/미국의 AI 규제 개요

생성형 AI가 급속하게 확산됨에 따라 각국 정부와 규제 기관은 인공지능 기술의 윤리적, 법적, 사회적 측면에 대한 규제 체계를 갖추기 시작하고 있습니다. 특히 GPT와 같은 강력한 생성형 모델이 등장하면서 개인정보 보호, 책임성, 저작권, 차별 방지, 투명성, 알고리즘 감시 등이 주요 이슈로 부각되고 있습니다.

이 절에서는 대한민국, 유럽연합(EU), 미국의 대표적인 AI 규제 체계와 법령/지침의 내용, 산업 적용 시 고려해야 할 요건을 국가별로 비교 분석합니다. 일본, 중국 등 여타 주요국에 대한 요약은 부록 A에서 추가 설명합니다.



### 1. 대한민국의 AI 규제 동향

대한민국은 AI 기술을 적극적으로 육성하면서도 ‘책임 있는 AI’라는 정책 기조 하에 신중한 규제 접근을 취하고 있으며, 2024년 현재로서는 포괄적인 AI 기본법은 입법되지 않았지만 세부 지침과 가이드라인 형태로 규제 프레임워크가 정비되고 있습니다.

#### (1) AI 법제화 진행 상황

- 「인공지능 기본법」(안)이 2023~2024년 사이 여러 차례 입법 발의되었으며, 주요 내용은 다음과 같습니다.
  - AI 기술의 안전한 개발 및 사용 환경 조성
  - 알고리즘 편향 및 차별 방지
  - AI 시스템의 설명 가능성(XAI) 확보
  - 개인정보 보호 및 민감 정보 처리 제한
  - 고위험 AI에 대한 평가 및 신고제 도입

- 현재는 과학기술정보통신부, 개인정보보호위원회, 방송통신위원회 등 여러 부처 주도로 가이드라인과 제도적 기반이 확립되고 있음.

#### (2) 주요 정부 가이드라인

- 과기정통부: 「신뢰할 수 있는 인공지능 구현을 위한 자율 규범」(2021)
- 개인정보보호위원회: 「AI 개인정보 보호 자율점검표」 등
- 방송통신위원회: 생성형 AI 이용 시 조작 콘텐츠(딥페이크 등) 표시 의무 등 추진 중

#### (3) 기업과 개발자 유의사항

- 생성형 AI 서비스 또는 SaaS를 출시하고 싶다면 다음을 반드시 고려해야 합니다.
  - 모델이 민감 정보(예: 주민번호, 건강정보)를 생성하거나 허위 정보를 유포하지 않도록 사전 사후 필터링 및 로깅 시스템 구축 필요
  - 사용자 동의 없는 개인정보 학습 방지 및 API 호출 로그의 암호화 저장
  - 서비스 설명서 및 TOS에 “AI가 생성한 내용”이라는 점을 명확히 고지하고, 오류가능성 명시



### 2. 유럽연합 (EU)의 AI 규제: AI Act

유럽연합(EU)은 세계 최초로 법적 구속력을 가지는 포괄적 AI 규제법인 「Artificial Intelligence Act (AI Act)」를 2024년에 최종 통과시켰습니다. 이 법은 AI 시스템의 위험도 기반 접근 방식을 채택하여 범용 적용을 목표로 하고 있으며, 글로벌 AI 서비스 기업에게도 상당한 법적 영향을 미칠 수 있습니다.

#### (1) AI Act의 핵심 구조

AI Act는 사용 목적 및 분야에 따라 AI 시스템을 다음 4단계로 분류합니다:

| 위험 수준       | 예시                               | 규제 수준          |
|----------------|------------------------------------|------------------|
| 금지된 AI       | 사회 점수화 시스템, 무의식적 조작 기법 | 전면 금지          |
| 고위험 AI       | 신용 평가, 교육 평가, 채용 필터링     | 엄격한 사전심사, 등록, 모니터링 의무 |
| 제한적인 위험 AI | 챗봇, 추천 시스템                   | 투명성 요구사항 부여   |
| 저위험 AI       | 일반적 생산성 도구                 | 최소한의 자율규제 수준  |

GPT와 같은 범용생성 모델(general purpose AI, GPAI)은 고위험 혹은 제한 위협 AI에 해당될 수 있으며, GPT-4는 특히 이 기준 하에서 주의가 필요한 사례입니다.

#### (2) 생성형 AI에 대한 별도 조항

- OpenAI 및 대형 AI 모델 제공자는 다음 요건을 따라야 함:
  - 학습 데이터 출처 공개 요구
  - 저작권을 침해할 가능성이 있는 콘텐츠에 대한 책임
  - 명확한 “AI 생성 콘텐츠” 표시
  - 설명 가능성, 재현성, 인간 개입 가능성 확보 요구

#### (3) 벌칙 및 기업 의무

- 규정 위반 시 최대 연매출의 6% 또는 3천만 유로 중 높은 금액을 벌금으로 부과
- AI 시스템 등록 및 리스크 평가 보고서 제출이 요구됨
- 모든 기업은 리스크에 맞는 품질 관리 시스템(QMS)을 보유해야 함

#### (4) 한국 기업에 미치는 영향

- 유럽 시장에 서비스를 제공하는 한국 기업도 AI Act를 준수해야 하며, 특히 다음과 같은 조치가 필요:
  - 유럽 데이터 주체의 개인 정보 및 편향 검출 필터링 사전내장
  - AI 모델의 훈련 데이터 중 저작권 이슈 유무 점검
  - 유럽 사용자를 위한 GDPR 및 AI Act 동시 준수 문서화



### 3. 미국의 AI 규제: 분산적이고 민간 주도 중심

미국은 연방 차원의 포괄적인 AI 규제법은 아직 마련되어 있지 않지만, 여러 행정 명령과 주(州) 단위의 규제, 기술 표준 중심의 자율 규제가 진행되고 있습니다. 규제보다는 혁신 촉진과 책임성 확보에 무게를 둔 접근입니다.

#### (1) 행정 명령 및 연방 정책

- 2023년 10월 바이든 행정부가 발표한 「Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence」가 핵심 정책 축입니다.
  - 모델 평가 및 리스크 분석 체계 도입
  - 국가안보/사이버보안 대응 AI 통제 강화
  - 민권(Civil rights) 확보 위한 알고리즘 공정성 확보
  - 저작권 침해 및 허위정보 방지 체계 마련

#### (2) NIST AI Risk Management Framework

- 미국표준기술연구소(NIST)가 2023년 발표한 「AI RMF (Risk Management Framework)」는 기업과 기관이 AI 도입 시, 신뢰성과 책임성을 확보할 수 있도록 로드맵을 제시한 지침
  - Fairness, Explainability, Safety, Transparency, Governance 등 요소 기반 평가

#### (3) 개별 주(State) 별 규제 예시

- 캘리포니아: 개인정보 보호법(CCPA) 기반으로 자동화된 결정에 대한 인간 개입권 보장
- 콜로라도, 일리노이: 얼굴 인식 기술과 생체정보 활용에 대한 제한
- 뉴욕시: 알고리즘 기반 HR 시스템 필터링 시 편향성 사전검토 의무화

#### (4) 산업 자율규제: Frontier Model Forum

- OpenAI, Anthropic, Google, Microsoft 등 미국 내 주요 AI 기업은 2023년부터 「Frontier Model Forum」을 구성해 자율 규제 및 투명성 확보 선언
  - 모델 안전성 평가(Safety certification)
  - 적절한 API 접근 제한(예: 무기로 사용 불가)
  - 고위험 사용 사례 차단 절차



### 4. 국가별 비교 정리

| 요소                             | 대한민국                                          | 유럽연합 (EU)                                | 미국                                            |
|----------------------------------|--------------------------------------------------|---------------------------------------------|-------------------------------------------------|
| 규제 성격                         | 권고 + 일부 법률 단계                            | 법적 구속력 있는 포괄법 (AI Act)             | 행정 법령 + 자율 규제 중심                        |
| 규제 프레임워크 도입 시기          | 2021년 이후 가이드라인, 법안은 진행 중           | 2024년 제정 완료                             | 2023년 행정명령 중심                            |
| 생성형 AI 특화 규정               | 아직 없음 (범용 가이드라인 적용)                | 고위험 AI에 포함되어 별도 조항 운영          | AI 생성물에 대한 저작권 / 허위정보 대응 언급        |
| 주요 규제 요구                     | 투명성, 책임성, 설명성, 개인정보 보호              | 데이터 출처 공개, AI 생성물 표시, XAI         | 알고리즘 감사, 민권보호, 사이버보안                   |
| 적용 대상                         | 국내 서비스 위주                                 | 유럽 이용자 대상 AI 시스템 모두 포함         | 연방 기관 대상 + 산업 자율 협약 기반               |



### 5. 정리 및 서비스 개발자가 유의해야 할 점

세계 각국의 AI 규제는 점점 더 정교해지고 있으며, 특히 생성형 AI의 경우 기존의 프라이버시 보호 규제(GDPR, CCPA 등) 외에도 다음과 같은 이슈에 주의할 필요가 있습니다:

- 생성된 콘텐츠에 대한 진위 표시 또는 ‘AI 생성’ 마크 의무
- 생성 데이터 혹은 학습 데이터 내 저작권 침해 이슈 여부
- 사용자 프롬프트 및 출력 내용에 포함된 편향 문제 필터링
- 사용자 데이터 수집 시 명시적 동의 및 거부권 제공
- 모델 평가와 리스크 평가 보고서의 정량적 관리 필요

따라서 OpenAI API를 활용한 서비스를 글로벌 시장에 제공하고자 한다면, 규제 준수는 기능적 품질 이상으로 핵심 경쟁 요소가 됩니다. 특히 개발 초기에 “AI 윤리/보안 설계”라는 관점에서 API 사용 로직, 로그 저장 설계, 사용자 인터페이스 설계를 치밀하게 고려해야 하며, 향후 실제 법제화가 국내 또는 해외에서 이루어질 가능성에 대해 기술적 유연성(Flexibility)을 확보해 두는 것이 바람직합니다.