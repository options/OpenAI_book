물론입니다. 『OpenAI API 실전 활용 완벽 가이드』의 Chapter 7.1 「함수 호출(Function Calling) 구조 이해」 절을 아래와 같이 자세하게 작성하겠습니다.



# Chapter 7. Function Calling & JSON Mode

## 7.1 함수 호출(Function Calling) 구조 이해

OpenAI의 GPT 모델은 기본적으로 자연어 입출력을 처리하지만, 2023년 GPT-4와 함께 도입된 "함수 호출(Function Calling)" 기능은 이러한 모델을 실제 외부 기능 호출이나 코드 실행과 연동되도록 만들어줍니다. 이를 통해 단순히 텍스트 응답을 넘는, 구조화된 출력 및 외부 시스템 통합이 가능한 강력한 LLM 애플리케이션을 설계할 수 있습니다.

이 절에서는 Function Calling의 작동 원리를 구조적으로 설명하고, 실제 사용 예제와 함께 그 활용 방법을 구체적으로 소개합니다.



## 7.1.1 Function Calling의 목적과 배경

Function Calling은 아래와 같은 주요 요구로 등장했습니다:

- {"name": ..., "args": ...} 형태의 구조화된 명령어 출력을 원하는 경우
- 대화의 흐름에서 특정 작업(날씨 조회, 계산 등)을 외부 함수로 위임하기 위함
- 사용자와 모델 간의 상호작용을 통해 실제 액션이 가능한 시스템 구축 목적

기존에는 모델이 다음과 같은 식으로 단순히 텍스트로 명령을 생성했습니다:

> “현재 위치의 날씨가 궁금하다면 /weather?location=Seoul 을 호출하세요.”

그러나 Function Calling을 사용하면, 모델이 다음처럼 직접적으로 파싱 가능한 JSON 명령을 반환합니다:

```json
{
  "function_call": {
    "name": "get_weather",
    "arguments": "{ \"location\": \"Seoul\" }"
  }
}
```

이를 통해 응답 내용을 파싱하고, 해당 기능을 코드로 실행한 후 다시 모델에 결과를 전달하는 패턴을 구현할 수 있습니다. 이는 곧 “모델을 API 호출 큐레이터”로 변모시키는 강력한 방식입니다.



## 7.1.2 작동 흐름 요약

Function Calling의 기본 동작 흐름은 다음과 같습니다:

1. 개발자가 openai.ChatCompletion.create() 호출 시 사용할 함수 사양(Function schema)을 함께 제공
2. 사용자의 메시지를 모델에게 전달
3. 모델이 사용자의 의도를 바탕으로 어떤 함수가 필요한지 판단
4. 그 함수 이름(name)과 인자(arguments)를 JSON 형식으로 반환 (function_call)
5. 클라이언트 측 또는 서버 로직에서 해당 함수를 실행
6. 실행 결과를 모델에 다시 전달하여 후속 응답 생성

흐름 다이어그램:

```
사용자 → GPT 모델 → 함수 호출 추론 → 서버/클라이언트에서 함수 실행 → 결과 응답 → 모델 → 사용자
```



## 7.1.3 Function Schema 정의 방법

함수 호출에 사용할 수 있는 함수의 "스키마"는 JSON Schema와 유사한 구조를 사용합니다. Python SDK를 예로 들면 다음처럼 정의합니다:

```python
functions = [
  {
    "name": "get_weather",
    "description": "특정 위치의 현재 날씨를 조회합니다.",
    "parameters": {
      "type": "object",
      "properties": {
        "location": {
          "type": "string",
          "description": "날씨를 알고 싶은 도시, 예: Seoul"
        },
        "unit": {
          "type": "string",
          "enum": ["celsius", "fahrenheit"],
          "description": "온도 단위"
        }
      },
      "required": ["location"]
    }
  }
]
```

여기서 중요한 요소는 다음과 같습니다:

- name: 모델이 호출할 함수 이름
- description: 모델이 함수의 용도를 이해할 수 있도록 도움을 줌 (명확할수록 모델이 잘 사용함)
- parameters: 이 함수가 받을 수 있는 매개변수의 구조 정의

※ 함수 명은 Snake case (예: get_weather) 등 코드와 일치하면 좋습니다. description은 짧고 명확하게 작성합니다.



## 7.1.4 모델 사용 및 Function Call 예제

실제 호출 예제를 보겠습니다. 아래는 OpenAI의 ChatCompletions API를 이용하여 날씨 정보를 가져오는 예제입니다.

```python
import openai

openai.api_key = "YOUR_API_KEY"

response = openai.ChatCompletion.create(
  model="gpt-4",
  messages=[{"role": "user", "content": "서울의 날씨가 어떤지 알려줘"}],
  functions=functions,  # 앞서 정의한 스키마
  function_call="auto"  # 또는 "none", {"name": "함수명"}
)

print(response["choices"][0]["message"])
```

기대 출력:

```json
{
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "get_weather",
    "arguments": "{ \"location\": \"서울\" }"
  }
}
```

이제 이 arguments를 실제 Python 함수와 연동하여 날씨 API에 요청하거나 더미 데이터를 반환한 후, 그 결과를 다시 모델에 전달할 수 있습니다.

예:

```python
# 함수 호출 예시
def get_weather(location, unit="celsius"):
    return f"{location}의 현재 기온은 15도입니다."

# 결과 전달용 메시지
function_response = get_weather("서울")
second_response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "user", "content": "서울의 날씨가 어떤지 알려줘"},
        response["choices"][0]["message"],  # function_call 메시지
        {
            "role": "function",
            "name": "get_weather",
            "content": function_response
        },
    ]
)

print(second_response["choices"][0]["message"]["content"])
```

이 과정을 통해 GPT는 사용자의 질문 → 구조적 함수 호출 유도 → 실행 결과를 받아 자연어 응답을 완료하는 한 사이클을 마치게 됩니다.



## 7.1.5 function_call="auto" / "none" / 수동 지정 해설

Function Call을 활성화하거나 제어하려면 아래 3가지 방식 중 하나를 선택합니다:

- function_call="auto"  
  GPT에게 판단을 맡깁니다. 사용자의 질문에 따라 필요한 함수가 있다면 호출합니다. 일반적인 사용에서 가장 편리함.

- function_call="none"  
  절대 함수 호출을 하지 않고, 일반 대화만 진행합니다. 디버깅 시 또는 함수 사용을 제한하고 싶은 경우에 사용.

- function_call={"name": "get_weather"}  
  특정 함수 호출을 강제로 지정합니다. 모델이 알아서 판단하지 않고 반드시 해당 함수 호출을 수행하게 됩니다. 테스트나 특정 플로우 유도 시 유용.



## 7.1.6 다수의 함수 등록과 선택

Function Calling은 여러 개의 함수를 동시에 등록할 수 있습니다. 이 경우, 모델은 사용자의 요청과 가장 일치하는 함수를 선택하려 시도합니다.

```python
functions = [
    {...},  # get_weather
    {
        "name": "calculate_tax",
        "description": "소득에 따른 세금 계산",
        ...
    },
    {
        "name": "lookup_product",
        "description": "제품 이름으로 가격 및 설명 조회",
        ...
    }
]
```

위와 같이 다수의 함수를 올려두면, 모델은 context에 맞는 함수를 선택해 호출하려고 시도합니다. 그러나 명확한 프롬프트와 함수 설명이 없으면 오탐 가능성도 있으므로, 컨텍스트 디자인에 유의해야 합니다.



## 7.1.7 실제 함수 실행 계층은 사용자 구현

중요한 점은, OpenAI API는 단지 “어떤 함수를 어떤 인자로 호출하면 좋겠다”를 제안해줄 뿐, 실제 해당 함수를 호출하거나 코드를 실행해주지는 않는다는 것입니다.

따라서 다음은 우리가 직접 수행해야 합니다:

- response에서 function_call을 판단
- arguments를 JSON으로 파싱
- 함수 이름에 맞는 실제 Python 함수 혹은 외부 API 실행
- 그 결과를 다시 모델에게 주기 위한 메시지를 구성

이러한 로직은 Flask, FastAPI 등의 백엔드 서버 위에서 처리되며, 실질적인 “AI Assistant System”의 핵심 로직을 구성하게 됩니다.



## 7.1.8 요약

| 항목 | 설명 |
|------|------|
| 목적 | GPT가 외부 함수나 API를 호출할 수 있도록 유도하고, 구조화된 출력을 얻기 위함 |
| 장점 | 도구 연동, 자연어 → 구조화 명령 전환, 자동 워크플로우 트리거 가능 |
| 핵심 구조 | function 사양 → function_call 출력 → 실제 함수 실행 → 응답 모델 전달 |
| 제약 | 직접 실행하지 않음, 인자 해석 오류 가능성 존재 |
| 활용 예 | 날씨 검색, 계산기, 검색 봇, DB 조회, 이메일 자동화, 스케줄러 등 |



다음 절(7.2)에서는 이러한 Function Calling 기능 위에 최근 추가된 JSON Mode의 차이점과 장점을 설명하며, 여러 응용 활용 예로 확장해 나가겠습니다.