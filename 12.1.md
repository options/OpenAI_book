Chapter 12. LangChain & LlamaIndex 연동

12.1 LangChain 기본 구조

LangChain은 대규모 언어 모델(LLM)의 실제 응용을 돕기 위한 오픈소스 프레임워크입니다. 단순 API 호출을 넘어서 언어 모델을 활용한 복합적인 애플리케이션(예: 문서 기반 Q&A, 다단계 추론, 에이전트 등)을 구축할 수 있도록 체계적인 컴포넌트와 통합 기능을 제공합니다. 이 절에서는 LangChain의 아키텍처를 구성하는 기본 요소들을 소개하고, LLM 기반 애플리케이션을 개발하는 데 어떤 방식으로 이를 활용할 수 있는지 설명합니다.

📌 목차

- 12.1.1 LangChain의 개요와 필요성
- 12.1.2 LangChain의 핵심 구성 요소
   - LLM(Large Language Model)
   - PromptTemplates
   - Chains
   - Agents
   - Tools
   - Memory
- 12.1.3 LangChain 모델 프로바이더(OpenAI, Cohere, Anthropic 등)
- 12.1.4 LangChain 실행 흐름: 입력 → 처리 → 출력
- 12.1.5 사용 예제: 단순 질의 응답 서비스 구현

 

12.1.1 LangChain의 개요와 필요성

LLM을 활용할 때 가장 자주 부딪히는 문제는 다음과 같습니다:

- "프롬프트를 어떻게 구성하고 관리할지?"
- "여러 API 호출이 필요할 때 상태를 어떻게 연결할지?"
- "사용자 대화 흐름에서 이전 맥락을 어떻게 기억할지?"
- "특정 기능(API, 계산기 등)을 LLM과 어떻게 연결할지?"

LangChain은 이런 문제를 해결하기 위해 만들어진 프레임워크로, LLM 기반의 응용 서비스를 빠르고, 확장 가능하며 구조적으로 개발할 수 있도록 고수준의 추상화를 제공합니다.

LangChain은 다음과 같은 기능을 목표로 합니다:

- 프롬프트 템플릿 관리의 편의성
- 단계적인 처리 흐름(체인)의 구성
- 외부 도구와 연동 가능한 에이전트 개념 제공
- 사용자 세션의 기억(Memory) 처리
- 다양한 모델 및 백엔드(Vector DB 등)과의 손쉬운 통합

 

12.1.2 LangChain의 핵심 구성 요소

LangChain은 여러 가지 강력한 컴포넌트로 구성됩니다. 각각의 기능을 명확히 이해해두면, 향후 복잡한 워크플로우 구성 시 큰 도움을 받을 수 있습니다.

🔹 1) LLM (Large Language Model)

LangChain은 OpenAI, Cohere, HuggingFace, Anthropic 등의 다양한 LLM 제공자를 추상화하여 동일한 방식으로 사용할 수 있게 해줍니다.

예시:

```python
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4", temperature=0.7)
```

🔹 2) PromptTemplate

PromptTemplate은 프롬프트 문자열을 템플릿화하여 대응되는 입력만 넣으면 자동으로 완성된 프롬프트를 만들어줍니다.

예시:

```python
from langchain.prompts import PromptTemplate

template = "학생 이름은 {name}이고, 나이는 {age}세입니다. 자기소개문을 만들어 주세요."
prompt = PromptTemplate(input_variables=["name", "age"], template=template)

formatted = prompt.format(name="지민", age="18")
# => "학생 이름은 지민이고, 나이는 18세입니다. 자기소개문을 만들어 주세요."
```

🔹 3) Chains

여러 단계를 거쳐 LLM을 호출하거나 외부 도구와 함께 작업을 수행해야 할 경우 Chain을 구성합니다.

SimpleChain → SequentialChain → CustomChain 등 다양한 유형이 있습니다.

예시 (LLMChain):

```python
from langchain.chains import LLMChain

chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run({"name": "지민", "age": 18})
```

🔹 4) Agents

Agent는 LLM에게 작업 목표만 알려주고 필요한 도구를 알아서 선택하고 순차적으로 사용합니다. 예를 들어, “서울 날씨 알려줘”라는 요청에 대해 LLM은 Weather API 툴을 호출하도록 지시받을 수 있습니다.

LangChain은 에이전트에게 Tool을 고르도록 유도하고, 상황에 따라 순환적으로 Tool 호출 + 응답 처리 + 다음 단계 계획을 반복합니다.

🔹 5) Tools

Tools는 에이전트가 사용할 수 있는 외부 유틸리티입니다. 예:

- 계산기
- 외부 API 호출기
- 웹 스크래퍼
- SQL DB 쿼리 도구
- 파일 검색기 등

예시:

```python
from langchain.agents import Tool

def multiply(a, b):
    return str(int(a) * int(b))

tool = Tool(
    name="곱셈 도구",
    func=lambda x: multiply(*x.split()),
    description="두 숫자를 곱합니다. 입력은 공백으로 구분된 숫자 두 개입니다."
)
```

🔹 6) Memory

LangChain의 Memory는 대화나 작업 중간 맥락을 저장하는 기능입니다. 사용자와의 이전 대화를 기억하여 다음 응답의 자연스러움을 증대시킬 수 있습니다.

기본적으로 ConversationBufferMemory, ConversationSummaryMemory 등이 제공됩니다.

예시:

```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
```

 

12.1.3 LangChain 모델 프로바이더 환경

LangChain은 특정 API 제공자(OpenAI, Anthropic 등)를 간편하게 추상화하여 다음과 같은 형태로 선택 구성할 수 있도록 지원합니다.

지원하는 주요 모델 제공자:

- OpenAI (gpt-3.5-turbo, gpt-4 등)
- HuggingFace Transformers
- Cohere
- Anthropic Claude
- Azure OpenAI

Chat 모델뿐 아니라 텍스트 생성, 임베딩 제공자도 통합되어 있어 동일한 구조로 다양한 백엔드 모델들과 연계가 가능합니다.

 

12.1.4 LangChain의 실행 흐름

LangChain을 활용한 일반적인 LLM 기반 서비스의 실행 흐름은 다음과 같은 단계를 거칩니다:

입력 (user query)  
→ PromptTemplate에 변수 삽입  
→ LLMChain 또는 Agent가 실행  
→ 필요 시 Tool 호출 (API, 계산기 등)  
→ 답변 생성  
→ Memory에 결과 저장 (선택적)  
→ 출력 반환

이를 통해 일회성 응답이 아닌, 상황에 따라 조건 분기, 외부 연동, 상태 유지까지 가능한 복합 응용 구조를 쉽게 구성할 수 있습니다.

 

12.1.5 사용 예제: 단순 질의 응답 앱 구성

LangChain을 이용한 간단한 Q&A 예제를 통해 구조를 정리해봅니다.

1️⃣ 필요한 패키지를 설치:

```bash
pip install langchain openai
```

2️⃣ API 키 설정:

```python
import os
os.environ["OPENAI_API_KEY"] = "your-key-here"
```

3️⃣ 기본 모듈 설정:

```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
prompt = PromptTemplate(
    input_variables=["question"],
    template="질문: {question}\n답변:"
)

chain = LLMChain(llm=llm, prompt=prompt)
```

4️⃣ 실행 예시:

```python
response = chain.run("한글은 누가 만들었나요?")
print(response)
```

▶︎ 결과:

```
한글은 조선 시대의 세종대왕이 직접 창제하였으며, 1443년에 창제되고 1446년에 반포되었습니다.
```

 

📌 정리

이 절에서는 LangChain의 핵심 아키텍처와 구성 요소 6개(LLM, PromptTemplate, Chain, Agent, Tool, Memory)를 자세히 살펴보았습니다. LangChain은 단일 프롬프트 응답 수준에서 벗어나, “워크플로우 기반 LLM 애플리케이션”을 만들기 위한 확장성과 유연성을 제공합니다. 다음 절에서는 이러한 요소를 활용하여 실제 문서 기반 Q&A 시스템과 같이 복잡한 구조를 어떻게 체계적으로 구축하는지 살펴보겠습니다.