## 9.4 다국어 자동 응답 구현

사용자와의 실시간 음성 인터랙션에서 가장 중요한 요소 중 하나는 다양한 언어를 사용하는 사용자들을 자연스럽게 응대할 수 있는 기능입니다. 글로벌 기업, 여행 플랫폼, 교육 서비스 등 사용자 기반이 다국어일 경우, 언어 장벽 없이 정확하고 빠른 피드백을 제공하는 것이 경쟁력으로 작용합니다.

OpenAI의 Whisper(STT)와 GPT(Chat Completion), 그리고 TTS(Text-to-Speech) API를 조합하면, 완전한 다국어 자동 응답 시스템을 구축할 수 있습니다. 이 절에서는 OpenAI API를 활용한 다국어 자동 응답 시스템의 설계 원리를 설명하고, 실습 예제와 함께 주요 고려 사항을 소개합니다.



### 🧱 1. 구성 요소 개요

다국어 응답 시스템은 다음의 주요 컴포넌트로 구성됩니다:

| 기능                  | 사용 API                            |
|---------------------|------------------------------------|
| 사용자 음성 입력 수집     | 마이크 녹음 (브라우저/모바일)          |
| 음성 → 텍스트 변환       | Whisper (Speech-to-Text API)        |
| 입력 언어 감지 및 처리     | GPT (Chat Completion API)           |
| 텍스트 → 텍스트 응답 생성 | GPT (언어/도메인에 맞는 프롬프트 설계) |
| 텍스트 → 음성 변환       | TTS (Text-to-Speech API)            |
| 다국어 출력            | TTS: 현재 5개 언어(영어/프랑스어/독일어/스페인어/이탈리아어) 지원 |

이 과정을 입력 → 이해 → 생성 → 출력의 흐름으로 정리하면 다음과 같습니다:

Audio input → Whisper STT (언어 자동 감지) → GPT(Chat) 응답 생성 → TTS 변환 → Audio Output



### 🌍 2. Whisper API를 통한 음성 인식과 언어 감지

Whisper는 음성 인식뿐 아니라 음성의 언어를 자동 감지할 수 있는 기능을 내장하고 있습니다. 이는 다국어 자동 응답 구현의 핵심 구성 요소 중 하나입니다.

Whisper는 음성 입력을 분석하여 원문 텍스트를 추출하고 동시에 언어 코드(예: "en", "ko", "es" 등)를 반환합니다.

🔧 Whisper 사용 예제 (Python):

```python
import openai

audio_file = open("sample_audio.mp3", "rb")

transcript = openai.Audio.transcribe(
    model="whisper-1",
    file=audio_file,
    response_format="verbose_json" # 언어 정보 포함
)

print("Detected Language:", transcript["language"])
print("Transcribed Text:", transcript["text"])
```

📌 결과 예시:

```json
{
  "language": "ko",
  "text": "안녕하세요, 고객 지원 센터입니다. 무엇을 도와드릴까요?"
}
```

이 결과를 바탕으로 다음 단계(GPT 응답)에서 언어에 맞는 프롬프트를 생성합니다.



### 💬 3. GPT 응답 생성: 다국어 문맥 반영

Whisper가 출력한 텍스트는 그대로 GPT Chat Completion API로 전달되어 응답 문장을 생성하게 됩니다. 이때 사용자 언어에 맞는 시스템 메시지를 구성하여 GPT가 언어에 맞는 응답을 하도록 유도할 수 있습니다.

🔧 메시지 예제:

```python
messages = [
    {"role": "system", "content": "You are a customer support agent that always replies in Korean."},
    {"role": "user", "content": "배송이 아직 도착하지 않았어요."}
]

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=messages,
    temperature=0.5
)

print(response["choices"][0]["message"]["content"])
```

💡 팁: 사용자 언어에 따라 system 메시지의 언어 및 안내 문구를 동적으로 조절합니다.

예:
- 한국어: "당신은 공손하고 친절한 한국어 고객 응대 챗봇입니다."
- 스페인어: "Respondes como un agente de atención al cliente en Español."

또한, 메시지 중간에 번역을 요청하거나, 다국어 응대가 필요한 경우 다음과 같이 처리할 수 있습니다:

```python
{"role": "user", "content": "Can you answer me in Spanish?"}
```

GPT 모델은 일반적으로 다국어 이해가 탁월하여 위와 같이 프롬프트만 잘 구성되면 자동 전환 응답까지 가능합니다. 하지만 언어 감지를 명시적으로 반영하여 GPT가 일관된 출력 언어를 유지하도록 하는 것이 더 정확하고 일관성 있는 결과를 만듭니다.



### 🔊 4. 응답을 TTS로 변환하여 음성 출력

GPT 응답이 생성된 후, 이를 다시 음성으로 변환하는 과정이 필요합니다. OpenAI의 TTS(Audio API)는 현재 다음 언어를 지원합니다:

- 영어 (en)
- 프랑스어 (fr)
- 독일어 (de)
- 스페인어 (es)
- 이탈리아어 (it)

한국어(Korean)는 아직 직접 지원되지 않지만, 다른 텍스트 음성 합성 서비스(Naver Clova, Google Cloud TTS 등)와 연동하면 커버가 가능합니다.

🔧 TTS (Text-to-Speech) 호출 예시:

```python
import openai

response = openai.audio.speech.create(
    model="tts-1",
    voice="nova",  # 또는 alloy, shimmer 등
    input="Your delivery is scheduled to arrive tomorrow."
)

with open("reply.mp3", "wb") as f:
    f.write(response.content)
```

📌 TTS 모델은 신경망 기반의 자연스러운 발화가 가능하며, 감정과 톤도 적절하게 유지합니다.

💡 한국어 응답이 필요할 경우, 외부 TTS 엔진을 연동하거나 텍스트로 유지하고 화면 표시 방식으로 대체하는 전략도 사용됩니다.



### 🧪 5. 종합 구축 예제: 간단한 플로우

다국어 자동 응답 시스템을 구성하는 간단한 정책 기반 플로우 예시는 다음과 같습니다:

```python
def process_audio(file_path):
    # 1. 음성 → 텍스트 변환 + 언어 감지
    transcript = openai.Audio.transcribe(
        model="whisper-1",
        file=open(file_path, "rb"),
        response_format="verbose_json"
    )
    lang = transcript["language"]
    user_text = transcript["text"]
    
    # 2. 사용자 언어 기반 지시문 준비
    system_prompts = {
        "ko": "당신은 친절한 한국어 고객 응대 챗봇입니다.",
        "en": "You are a helpful English customer support assistant.",
        "es": "Respondes como un agente de soporte al cliente en español.",
        # 필요한 언어 추가
    }
    system_message = system_prompts.get(lang, system_prompts["en"])

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_text}
    ]
    
    # 3. GPT 응답 생성
    chat_response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages
    )
    reply = chat_response["choices"][0]["message"]["content"]
    
    # 4. TTS (지원 언어일 경우에만)
    supported_tts_langs = ["en", "fr", "es", "de", "it"]
    if lang in supported_tts_langs:
        audio_response = openai.audio.speech.create(
            model="tts-1",
            voice="nova",
            input=reply
        )
        with open(f"reply_{lang}.mp3", "wb") as f:
            f.write(audio_response.content)
        return f"reply_{lang}.mp3"
    else:
        return reply  # 한국어 등은 텍스트 응답
```



### ⚠️ 6. 주요 고려 사항

| 항목                | 설명 |
|--------------------|------|
| 언어 구분 정확도      | Whisper는 일반적으로 높은 정확도의 언어 자동 감지를 제공하지만, 한국어와 일본어, 중국어처럼 발음 유사도가 높은 언어에서는 간혹 혼동이 발생할 수 있음 |
| 언어 코드 매핑       | 각 기능(TTS 등)이 지원하는 언어 코드와 Whisper 감지 결과를 일치시키는 전처리 필요 |
| 맥락 유지            | 다국어 전환이 빈번한 대화에서는 사용자 언어 히스토리 관리를 통해 연속성 유지 필요 |
| TTS 음성 자연스러움  | 고객 응대 수준에서는 표현 조절과 발화 간 음성 딜레이가 품질에 직접 영향 |
| 로컬라이징           | 단어 그대로 번역보다는 문화/문맥에 맞는 지역화된 텍스트 응답을 고려해야 GPT 응답의 만족도가 향상됨 |



### ✅ 7. 요약

- Whisper로 음성 입력을 다국어로 정확히 받아들이고,
- 감지된 언어에 따라 GPT 응답을 생성하며,
- 가능하면 해당 언어로 음성화하는 일련의 파이프라인이 다국어 자동 응답 시스템의 핵심입니다.
- TTS의 지원 언어 범위가 제한적이기 때문에 한국어 등은 외부 TTS 도구를 활용한 보완이 필요할 수 있습니다.

이러한 기술적 흐름을 자동화하면, 전화 응대, 대화형 챗봇, 키오스크 인터페이스 등 다양한 환경에서 실시간 다국어 고객 응대가 가능해집니다. 고객 경험을 혁신하는 핵심 기능으로 발전시킬 수 있습니다.